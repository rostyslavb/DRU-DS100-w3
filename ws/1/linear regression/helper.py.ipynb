{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_regression():\n",
    "    # Step # 1 - Extract data\n",
    "    points = np.genfromtxt('data.csv', delimiter=',')\n",
    "    \n",
    "    # Step # 2 - Define hyperparameters\n",
    "    \n",
    "    ## Learning rate\n",
    "    learning_rate = 0.0001\n",
    "    \n",
    "    ## Coefficients y = a * x + b\n",
    "    init_a = 0\n",
    "    init_b = 0\n",
    "    \n",
    "    ## number of iterations\n",
    "    num_iterations = 10000\n",
    "    \n",
    "    # Step 3 - model training\n",
    "    \n",
    "    print(\n",
    "        'Start learning at a = {0}, b = {1}, error = {2}'.format(\n",
    "            init_a,\n",
    "            init_b,\n",
    "            compute_error(init_a, init_b, points)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    a, b = gradient_descent(init_a, init_b, points, learning_rate, num_iterations)\n",
    "    \n",
    "    print(\n",
    "        'End learning at a = {0}, b = {1}, error = {2}'.format(\n",
    "            a,\n",
    "            b,\n",
    "            compute_error(a, b, points)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return a, b\n",
    "\n",
    "\n",
    "def compute_error(a, b, points):\n",
    "    '''\n",
    "        Computes Error = 1/N * sum((y - (ax + b))^2)\n",
    "    '''\n",
    "    error = 0\n",
    "    N = len(points)\n",
    "    \n",
    "    for i in range(N):\n",
    "        x = points[i, 0]\n",
    "        y = points[i, 1]\n",
    "        \n",
    "        error += (y - (a * x + b)) ** 2\n",
    "\n",
    "    return error / N\n",
    "\n",
    "\n",
    "def gradient_descent(starting_a, starting_b, points, learning_rate, num_iterations):\n",
    "    '''\n",
    "        Performs gradient step num_iterations times\n",
    "        in order to find optimal a, b values\n",
    "    '''\n",
    "    a = starting_a\n",
    "    b = starting_b\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        a, b = gradient_step(a, b, points, learning_rate)\n",
    "    \n",
    "    return a, b\n",
    "    \n",
    "def gradient_step(current_a, current_b, points, learning_rate):\n",
    "    '''\n",
    "        Updates a and b in antigradient direction\n",
    "        with given learning_rate\n",
    "    '''\n",
    "    a = current_a\n",
    "    b = current_b\n",
    "    \n",
    "    a_gradient = 0\n",
    "    b_gradient = 0\n",
    "    \n",
    "    N = len(points)\n",
    "    \n",
    "    for i in range(N):\n",
    "        x = points[i, 0]\n",
    "        y = points[i, 1]\n",
    "        \n",
    "        a_gradient += - (2 / N) * x * (y - (a * x + b))\n",
    "        b_gradient += - (2 / N) * (y - (a * x + b))\n",
    "    \n",
    "    a = current_a - learning_rate * a_gradient\n",
    "    b = current_b - learning_rate * b_gradient\n",
    "    \n",
    "    return a, b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python35]",
   "language": "python",
   "name": "conda-env-python35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
